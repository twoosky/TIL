# Broker
* Kafka에서 Broker는 producer와 consumer 사이의 데이터를 주고받기 위해 사용하는 주체
* 데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와주는 애플리케이션
* 하나의 서버에는 한 개의 Kafka Broker 프로세스가 실행된다.
* 데이터를 안전하게 보관하고 처리하기 위해 일반적으로 3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 운영한다.
* 카프카 클러스터로 묶인 브로커들은 producer가 보낸 데이터를 안전하게 분산 저장하고 복제하는 역할을 수행한다.
## Broker의 역할
**1. 컨트롤러**
* 컨트롤러의 다수 브로커 중 한 대가 컨트롤러의 역할을 한다.
* 컨트롤러는 다른 브로커들의 상태(생존 여부)를 체크한다.
* 만약 임의의 브로커가 중단되었을 경우, 해당 브로커에 있던 리더 파티션을 탈락시키고, 팔로워 파티션 중 하나를 리더로 뽑는다.
* 컨트롤러 역할을 하는 브로커에 장애가 생기면 다른 브로커가 컨트롤러 역할을 한다.

**2. 데이터 삭제**
* 카프카는 consumer가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않는다.
* 또한, consumer나 producer가 데이터 삭제를 요청할 수도 없다.
* 오직 브로커만이 데이터를 삭제할 수 있다.
* 데이터 삭제는 파일 단위로 이루어지는데 이 단위를 로그 세그먼트(log segment)라고 한다.

**3. 컨슈머 오프셋 저장**
* consumer group은 토픽을 특정 파티션으로부터 데이터를 가져가 처리하고, 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋(offset)을 커밋한다.
* 커밋한 오프셋은 __consumer_offsets 토픽에 저장한다.
* 여기에 저장된 오프셋을 토대로 컨슈머 그룹은 다음 레코드를 가져가 처리한다.

**4. 그룹 코디네이터**
* 카프카 클러스터 내 브로커 중 한 대는 코디네이터 역할을 수행한다.
* 코디네이터는 컨슈머 그룹의 상태를 체크하고, 각각의 파티션을 consumer와 매핑되도록 분배하는 역할을 한다.
* 만약 컨슈머에 장애가 발생한 경우, 해당 컨슈머와 매핑되어 있는 파티션을 정상 작동 중인 컨슈머로 재할당한다.
* 파티션을 컨슈머로 재할당하는 과정을 `리밸런스(rebalance)`라고 한다.

**5. 데이터 저장**
* 브로커는 producer로부터 전달받은 데이터를 config/server.properties/의 log.dir 옵션으로 정의한 디렉토리에 저장한다.
* 토픽 이름과 파티션 번호의 조합으로 하위 디렉토리를 생성하여 데이터를 저장한다.
* 오프셋은 레코드를 구분하는 식별자 역할이며, 레코드 삽입에 따라 0부터 꾸준히 증가한다.
* 예시 : hello.kafka 토픽의 0번 파티션에 존재하는 데이터 확인
  * log : 메시지(레코드)와 메타데이터 저장
  * index : 메시지의 오프셋을 인덱싱한 정보를 담은 파일
  * timeindex : 메시지에 포함된 timestamp값을 기준으로 인덱싱한 정보 저장
<img src="https://github.com/twoosky/TIL/assets/50009240/d1641fef-8f02-45dc-999a-e31d2c8e0edc" width="700" height="160">

## 로그와 세그먼트
<img src="https://github.com/twoosky/TIL/assets/50009240/474cd103-6ce0-4c5b-bf4e-e2249dc24357" width="700" height="290">

**저장**
* offset은 producer에서 브로커로 전달한 데이터인 레코드의 고유 번호
* `log.segment.bytes` : 바이트 단위의 최대 세그먼트 크기 지정. 기본값은 1GB
* `log.roll.ms(hours)` : 세그먼트가 신규 생성된 이후 다음 파일로 넘어가는 시간 주기. 기본값은 7일

**삭제**
* 가장 마지막 세그먼트(쓰기가 일어나고 있는 파일)인 active 세그먼트 외 세그먼트들은 옵션에 따라 삭제된다.
* 삭제 옵션(cleanup.policy)에는 delete와 compact가 있다.
* delete
  * 세그먼트 보유 기간 등의 설정에 의해 세그먼트 단위로 삭제
  * 카프카에서 데이터는세그먼트 단위로 삭제가 발생하기 때문에 로그(레코드) 단위로 개별 삭제는 불가능하다.
* compact
  * 메시지 키 별로 해당 메시지 키의 레코드 중 오래된 데이터를 삭제하는 정책
  * 일부 레코드만 삭제 가능
